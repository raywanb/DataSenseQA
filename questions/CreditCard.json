[
    {
        "question": "Calculate the mean, median, and mode of the current_age column.",
        "ground_truth": "Mean Age: 45.57 years, Median Age: 43.00 years, Mode Age: 18 years",
        "derivation": "df['current_age'].mean(); df['current_age'].median(); df['current_age'].mode()",
        "difficulty": "easy",
        "subtype": "Descriptive Statistics",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Determine the range of credit_score and calculate its standard deviation",
        "ground_truth": "Range: 370, Std: 67.22",
        "derivation": "range = df['credit_score'].max() - df['credit_score'].min(); std = df['credit_score'].std()",
        "difficulty": "medium",
        "subtype": "Descriptive Statistics",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Find the interquartile range (IQR) of yearly_income and total_debt and compare them to identify which has a wider spread.",
        "ground_truth": "Yearly Income:\nQ1: $32,818.50\nQ3: $52,698.50\nIQR: $19,880.00\n\nTotal Debt:\nQ1: $23,986.75\nQ3: $89,070.50\nIQR: $65,083.75\n\nIQR Difference (Income - Debt): $-45,203.75",
        "derivation": "df['yearly_income'] = df['yearly_income'].str.replace('$', '').str.replace(',', '').astype(float); df['total_debt'] = df['total_debt'].str.replace('$', '').str.replace(',', '').astype(float); q1_income = df['yearly_income'].quantile(0.25); q3_income = df['yearly_income'].quantile(0.75); iqr_income = q3_income - q1_income; q1_debt = df['total_debt'].quantile(0.25); q3_debt = df['total_debt'].quantile(0.75); iqr_debt = q3_debt - q1_debt",
        "difficulty": "hard",
        "subtype": "Descriptive Statistics",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Determine the interquartile range (IQR) of credit_score, num_credit_cards, and retirement_age. Identify which of these three attributes shows the least variability. Additionally, compute the median for each attribute and discuss the relationship between the IQR and median values.",
        "ground_truth": "Credit Score:\nQ1: 681\nQ3: 753\nIQR: 72\nMedian: 711.5\n\nNumber of Credit Cards:\nQ1: 2\nQ3: 4\nIQR: 2\nMedian: 3\n\nRetirement Age:\nQ1: 65\nQ3: 68\nIQR: 3\nMedian: 66\n\nComparison:\nLeast Variability: Number of Credit Cards (IQR: 2).\nRelationship with Median: The attribute with the smallest IQR (Number of Credit Cards) also has the smallest median value (3). Credit Score and Retirement Age have higher medians and IQRs, indicating broader variability in these distributions.",
        "derivation": "q1_credit_score = data['credit_score'].quantile(0.25); q3_credit_score = data['credit_score'].quantile(0.75); iqr_credit_score = q3_credit_score - q1_credit_score; median_credit_score = data['credit_score'].median(); q1_credit_cards = data['num_credit_cards'].quantile(0.25); q3_credit_cards = data['num_credit_cards'].quantile(0.75); iqr_credit_cards = q3_credit_cards - q1_credit_cards; median_credit_cards = data['num_credit_cards'].median(); q1_retirement_age = data['retirement_age'].quantile(0.25); q3_retirement_age = data['retirement_age'].quantile(0.75); iqr_retirement_age = q3_retirement_age - q1_retirement_age; median_retirement_age = data['retirement_age'].median();",
        "difficulty": "hard",
        "subtype": "Descriptive Statistics",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },    
    {
        "question": "Count the frequency of each gender value in the dataset.",
        "ground_truth": "Female 1016, Male 984",
        "derivation": "gender_counts = df['gender'].value_counts()",
        "difficulty": "easy",
        "subtype": "Frequency and Distribution Analysis",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Calculate the percentage of individuals with a credit_score above 750.",
        "ground_truth": "26.2%",
        "derivation": "df[df['credit_score'] > 750] / len(df)",
        "difficulty": "medium",
        "subtype": "Frequency and Distribution Analysis",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Analyze the seasonality of births, by grouping into seasons, and calculate the percent distribution, and determine if there is statistical significance between peak and low seasons with a chi2 test.",
        "ground_truth": "Seasonal Distribution:\nWinter: 27.7%\nFall: 25.9%\nSpring: 23.6%\nSummer: 22.8%\n\nPeak Season: Winter\nLow Season: Summer\n\nChi-square test results:\nChi-square statistic: 11.74\np-value: 0.0083\nSignificant difference from uniform distribution: True",
        "derivation": "season_mapping = {12: 'Winter', 1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring', 6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Fall', 10: 'Fall', 11: 'Fall'}; df['season'] = df['birth_month'].map(season_mapping); season_counts = df['season'].value_counts(); season_percentages = df['season'].value_counts(normalize=True) * 100; peak_season = season_counts.index[0]; low_season = season_counts.index[-1]; expected_freq = len(df) / 4; chi2_stat, p_value = stats.chisquare(season_counts, [expected_freq] * 4)",
        "difficulty": "hard",
        "subtype": "Frequency and Distribution Analysis",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Analyze the frequency distribution of credit scores by grouping them into ranges (poor, fair, good, excellent). Calculate the percent distribution and determine if there is a statistically significant difference between observed and expected distributions using a chi2 test.",
        "ground_truth": "Credit Score Distribution:\nPoor (300–579): 4.05%\nFair (580–669): 17.40%\nGood (670–739): 46.55%\nExcellent (740–850): 32.00%\n\nChi-square Test Results:\nChi-square statistic: 808.05\np-value: 7.76 × 10⁻¹⁷⁵\nSignificant difference from uniform distribution: True",
        "derivation": "from scipy import stats; bins = [300, 579, 669, 739, 850]; labels = ['Poor', 'Fair', 'Good', 'Excellent']; df['credit_score_range'] = pd.cut(df['credit_score'], bins=bins, labels=labels, include_lowest=True); range_counts = df['credit_score_range'].value_counts(); range_percentages = df['credit_score_range'].value_counts(normalize=True) * 100; observed = range_counts.values; expected = [len(df) / len(labels)] * len(labels); chi2_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected);",
        "difficulty": "hard",
        "subtype": "Frequency and Distribution Analysis",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },    
    {
        "question": "Calculate the correlation between current_age and retirement_age.",
        "ground_truth": "0.0048",
        "derivation": "correlation = df['current_age'].corr(df['retirement_age'])",
        "difficulty": "easy",
        "subtype": "Correlation and Association",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Analyze whether there is a correlation between yearly_income, total_debt, and credit_score by computing a correlation matrix for these variables.",
        "ground_truth": "yearly_income  total_debt  credit_score\nyearly_income          1.000       0.551         0.000\ntotal_debt             0.551       1.000        -0.105\ncredit_score           0.000      -0.105         1.000",
        "derivation": "df[['yearly_income', 'total_debt', 'credit_score']].corr()",
        "difficulty": "hard",
        "subtype": "Correlation and Association",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Identify trends in credit score based on current age.",
        "ground_truth": "There is not really trends between these two as the correlation is 0.0396.",
        "derivation": "correlation = df['current_age'].corr(df['credit_score'])",
        "difficulty": "hard",
        "subtype": "Trend Analysis",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Identify trends in yearly income vs lat, long from the point lat, long (40, -120).",
        "ground_truth": "There is not really trends between these two as the correlation is -0.005.",
        "derivation": "correlation = df[['yearly_income', 'latitude', 'longitude']].corr()",
        "difficulty": "hard",
        "subtype": "Trend Analysis",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Group individuals by birth_month and analyze seasonal patterns in credit_score and total_debt. Determine if these patterns are statistically significant and quantify the extent to which birth_month explains the variability in these two columns using an ANOVA test.",
        "ground_truth": "Both credit score and total debt show no statistically significant seasonal patterns based on birth month (p-values > 0.05). The ANOVA F-Statistic for credit score is 1.56 with a p-value of 0.105, and birth month explains only 0.9% of its variability (R-squared: 0.009). Similarly, the ANOVA F-Statistic for total debt is 1.24 with a p-value of 0.256, and birth month explains only 0.8% of its variability (R-squared: 0.008).",
        "derivation": "from scipy.stats import f_oneway; df['total_debt'] = pd.to_numeric(df['total_debt'].str.replace('[^\d.]', ''), errors='coerce'); data_cleaned = df.dropna(subset=['birth_month', 'credit_score', 'total_debt']); anova_credit_score = f_oneway(*[group['credit_score'] for _, group in data_cleaned.groupby('birth_month')]); anova_total_debt = f_oneway(*[group['total_debt'] for _, group in data_cleaned.groupby('birth_month')]); credit_score_r_squared = data_cleaned.groupby('birth_month')['credit_score'].mean().var() / data_cleaned['credit_score'].var(); total_debt_r_squared = data_cleaned.groupby('birth_month')['total_debt'].mean().var() / data_cleaned['total_debt'].var();",
        "difficulty": "hard",
        "subtype": "Trend Analysis",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Test if the mean credit_score differs significantly between males and females using a t-test.",
        "ground_truth": "t-statistic: 0.38, p-value: 0.704. Since the p-value is much greater than the common significance level of 0.05, we fail to reject the null hypothesis.",
        "derivation": "from scipy.stats import ttest_ind; males = df[df['gender'] == 'Male']['credit_score']; females = df[df['gender'] == 'Female']['credit_score']; t_stat, p_value = ttest_ind(males, females, equal_var=False)",
        "difficulty": "easy",
        "subtype": "Hypothesis Testing",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Perform a chi-square test to see if gender and having num_credit_cards > 3 are independent.",
        "ground_truth": "Chi-square statistic: 0.416, p-value: 0.519, Degrees of freedom: 1. Since the p-value is greater than the common significance level of 0.05, we fail to reject the null hypothesis. This suggests that gender and having more than 3 credit cards are independent in this dataset.",
        "derivation": "from scipy.stats import chi2_contingency; df['num_credit_cards_gt_3'] = df['num_credit_cards'] > 3; contingency_table = pd.crosstab(df['gender'], df['num_credit_cards_gt_3']); chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)",
        "difficulty": "medium",
        "subtype": "Hypothesis Testing",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Test if the variance in yearly_income is significantly different between individuals with credit_score above and below 700.",
        "ground_truth": "Levene statistic: 0.141, p-value: 0.707. Since the p-value is greater than the common significance level of 0.05, we fail to reject the null hypothesis.",
        "derivation": "from scipy.stats import levene; above_700 = df[df['credit_score'] > 700]['yearly_income']; below_700 = df[df['credit_score'] <= 700]['yearly_income']; levene_stat, p_value_levene = levene(above_700, below_700, center='mean')",
        "difficulty": "medium",
        "subtype": "Hypothesis Testing",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Test if the variance in yearly_income is significantly different between individuals with more than 3 credit cards and those with 3 or fewer credit cards.",
        "ground_truth": "Levene statistic: 0.044, p-value: 0.834. Since the p-value is greater than the common significance level of 0.05, we fail to reject the null hypothesis. This means there is no significant difference in the variances of yearly_income between the two groups.",
        "derivation": "from scipy.stats import levene; above_3_cards = df[df['num_credit_cards'] > 3]['yearly_income']; below_3_cards = df[df['num_credit_cards'] <= 3]['yearly_income']; levene_stat, p_value_levene = levene(above_3_cards, below_3_cards, center='mean')",
        "difficulty": "medium",
        "subtype": "Hypothesis Testing",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },    
    {
        "question": "Compute a 95% confidence interval for the mean total debt of individuals with a credit score above 700.",
        "ground_truth": "($57,447.05, $63,523.65)",
        "derivation": "mean_debt_simple = filtered_data['total_debt'].mean(); std_dev = filtered_data['total_debt'].std(); n = len(filtered_data['total_debt'].dropna()); std_error = std_dev / math.sqrt(n); t_critical = 1.96; margin_of_error = t_critical * std_error; lower_bound = mean_debt_simple - margin_of_error; upper_bound = mean_debt_simple + margin_of_error",
        "difficulty": "medium",
        "subtype": "Confidence Interval",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Calculate a 95% confidence interval for the average yearly_income.",
        "ground_truth": "(44708.20471428665, 46723.559285713345)",
        "derivation": "from scipy.stats import norm; mean_yearly_income = data['yearly_income'].mean(); std_yearly_income = data['yearly_income'].std(); n = len(data['yearly_income']); se_yearly_income = std_yearly_income / np.sqrt(n); confidence = 0.95; z_score = norm.ppf((1 + confidence) / 2); margin_of_error = z_score * se_yearly_income; ci_lower = mean_yearly_income - margin_of_error; ci_upper = mean_yearly_income + margin_of_error",
        "difficulty": "easy",
        "subtype": "Confidence Interval",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    },
    {
        "question": "Compute a 90% confidence interval for the average credit_score.",
        "ground_truth": "707.26 to 712.21",
        "derivation": "from scipy.stats import norm; mean_credit_score = data['credit_score'].mean(); std_credit_score = data['credit_score'].std(); n = len(data['credit_score']); se_credit_score = std_credit_score / np.sqrt(n); confidence = 0.90; z_score = norm.ppf((1 + confidence) / 2); margin_of_error = z_score * se_credit_score; ci_lower = mean_credit_score - margin_of_error; ci_upper = mean_credit_score + margin_of_error",
        "difficulty": "easy",
        "subtype": "Confidence Interval",
        "type": "statistics",
        "table_path": "./datasets/demographics/users_data.csv"
    }
]
